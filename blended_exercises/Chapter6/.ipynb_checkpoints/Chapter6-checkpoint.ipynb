{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to Bayes-ics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please ensure you have watched the Chapter 6 video(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You will learn the following things in this Chapter\n",
    "\n",
    "- The idea of a conjugate prior and why they are useful.\n",
    "- The interplay between priors and new data.\n",
    "- Use Bayes Theorem on standard forms of probability density functions.\n",
    "- Use this to do hypothesis testing in the Bayes framework.\n",
    "- How to use Python programming to do the above.\n",
    "- After completing this notebook you will be able to start CA 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously (Chapter 2) we used Bayes Theorem to find the probability of A | B using discrete data points, but here we will see that we can also use it to find the probability density function that some model or model parameter explains the data given the data we measure and some previously measured values or estimates at the parameter (the prior). Let's remind ourselves that:\n",
    "\n",
    "$P(\\theta | D) = \\dfrac{ P(D | \\theta) P(\\theta)} { P(D)}.$\n",
    "\n",
    "Let's recap the terms:\n",
    "\n",
    "- $P(\\theta | D)$ the **posterior** - the probability of model parameter $\\theta$ being true, given the data\n",
    "- $ P(D | \\theta) $ the **likelihood** - given model parameter $\\theta$ what is likelihood of obtaining the data\n",
    "- $ P(\\theta)$ the **prior** - the probability of the model parameter $\\theta$ being ‘true’\n",
    "- $P(D)$ the **evidence** - the probability of getting the data, give all possible model parameter values ($\\theta$ and others!)\n",
    "\n",
    "In this Chapter we'll take a look at some classic examples where we can (easily) analytically solve the equations to get the model parameters out (which for us are the mean and standard deviation) out of the data we observe.  From above we can see that the posterior probability is what we want to calculate, the prior is what we think we already know about the population, and the likelihood is the likelihood of obtaining our data given the measured mean and standard deviation.\n",
    "\n",
    "We will look at 2 common situations:\n",
    "- a likelihood that can be described by a normal distribution\n",
    "- a likelihood that can be described by a bernoulli/binomial distribution\n",
    "\n",
    "Before we do this, we also define the term **conjugate prior**. This is one that has the same functional form as the posterior. If the likelihood is normally distributed, then the choice of a normal prior will ensure that the posterior is also a normal, and as such, our prior can be said to be conjugate. This is generally a good thing! \n",
    "\n",
    "Even if the true functional form of the posterior is *not* conjugate, it is common practise to approximate the prior distribution with a function that is, simply because it makes the mathematics easier, and it makes the functions behave! *Note that the prior is only conjugate when we consider likelihoods of a certain functional form.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal likelihood - normal prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytical expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we have a set of observations $X = {x_1, x_2, \\ldots, x_n}$ of some quantity that we believe to have been drawn from a normal distribution. We can then write,\n",
    "\n",
    "$p(x|\\theta) = N(\\theta, \\sigma)$\n",
    "\n",
    "where $\\theta$ is the mean value of the distribution (unknown) and $\\sigma$ describes the width (known).\n",
    "\n",
    "We can then also write the probability of the mean of the sample, $\\hat X$, as,\n",
    "\n",
    "$p(\\hat X | \\theta) = N(\\theta, \\sigma/\\sqrt{n})$\n",
    "\n",
    "Notice that now we do not use $\\sigma$ as the error since as we make more measurements, our estimate of the mean gets better (recall the difference between the error and the standard error on the mean!).\n",
    "\n",
    "Now suppose that we have some data from a previous study that reports a value for $\\theta$ of $\\mu_0$, with an associated error, $\\sigma_0$. This study was also subject to random errors, so we are free to write,\n",
    "\n",
    "$p(\\theta) = N(\\mu_0, \\sigma_0)$\n",
    "\n",
    "Bayes theorem allows us to combine this information to determine the PDF of $\\theta$.  Since the denominator is the integral over all $\\theta$, it is just a constant, and so it doesn't affect the shape of the posterior, only the height. As such, we can ignore it for the moment, and focus on the numerator (i.e. the likelihood $\\times$ prior).\n",
    "\n",
    "Since both the likelihood and prior are normal distributions, the posterior must also be a normal distribution, this leads to the following expressions for the mean and variance of the posterior.\n",
    "\n",
    "$ \\hat{\\theta}  = \\dfrac{\\sigma_0^2}{\\sigma_0^2 + \\sigma^2/n} \\hat{X}   +  \\dfrac{\\sigma^2/n} {\\sigma_0^2 + \\sigma^2/n} \\mu_0\n",
    "$\n",
    "\n",
    "$\\hat{\\sigma}^2 =  \\dfrac{\\sigma_0^2 \\sigma^2/n} {\\sigma_0^2 + \\sigma^2/n}.$\n",
    "\n",
    "A nice way of thinking about this interplay between the prior and likelihood, is to imagine that the prior is simply adding another data point. If this data point is good (i.e. small variance, such that it is strongly peaked around the mean), then the prior pulls the posterior towards it. If the prior is vague, then it behaves like a data point with a big error, and the posterior relies on the data to provide the underlying shape. This is same behaviour, and indeed very similar maths, to the idea of *weighted averages* that we discussed in Chapter 5.\n",
    "\n",
    "**Good and Bad Data**\n",
    "\n",
    "When the data is good (eg if $\\sigma$ is small, and/or $n$ is large), the equation for the mean above shows that the 1st term will tend to one and the second term to zero, the *posterior will favour the data over the prior*. \n",
    "\n",
    "When the data is bad (eg if $\\sigma$ is large, and/or $n$ is small), the equation for the mean above shows that the 1st term will tend to one and the second term to zero, the *posterior will favour the prior over the data*. \n",
    "\n",
    "So to recap, the figure below summarises what we need to do to get the Bayesian probability density function (posterior) from the prior and likelihood, and how we may then get out statistics such as mean, variance etc.\n",
    "\n",
    "<img src=\"https://github.com/haleygomez/Data-Analysis-2021/raw/master/blended_exercises/Chapter6/bayespdf.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#4290C4>Example</font>\n",
    "\n",
    "Ten 20-year old students have their heights measured (in cm) with variance of 50cm resulting in the following data:\n",
    "\n",
    "\n",
    "heights = 169.6, 166.8, 157.1, 181.1, 158.4, 165.6, 166.7, 156.5, 168.1, 165.3\n",
    "\n",
    "\n",
    "A previous set of (normally distributed) measurements said the mean and standard deviation of heights is 170  ±  3cm.\n",
    "\n",
    "\n",
    "Assuming that the heights are drawn from a normal distribution, state what shape the posterior distribution has and derive the mean and standard deviation of the posterior distribution.\n",
    "\n",
    "Plot the data you observe as a histogram. Also plot the PDFs for the likelihood and the prior. \n",
    "\n",
    "Plot the posterior PDF and overplot the mean of the posterior (tip: `plt.axvline(value)` plots a vertical line). Briefly discuss what you see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color=#c38241> Solution</font>\n",
    "\n",
    "Click below to see the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# function for mean of posterior if posterior normal\n",
    "def post_mean(var_0,var,n,X,mu_0):\n",
    "    result = (var_0/ (var_0 + (var/n)) ) * X + ((var/n)/(var_0+(var/n)))*mu_0\n",
    "    return result\n",
    "\n",
    "# function for width (standard dev) of posterior if posterior normal\n",
    "def post_std(var_0,var,n):\n",
    "    result = np.sqrt((var_0*(var/n)) / (var_0 + (var/n)))\n",
    "    return result\n",
    "\n",
    "ht = [169.6,166.8,157.1,181.1,158.4,165.6,166.7,156.5,168.1,165.3]\n",
    "n = len(ht)\n",
    "\n",
    "var = 50.\n",
    "err_mean = np.sqrt(var/n)\n",
    "\n",
    "data_mean = np.mean(ht)\n",
    "data_var = var\n",
    "prior_var = 3**2.\n",
    "prior_mean = 170. \n",
    "\n",
    "# set up an array\n",
    "d = np.linspace(150,180,100)\n",
    "\n",
    "# these are normal distributions so \n",
    "# can use the analytical equations from the notes for posterior\n",
    "# mean and standard deviation\n",
    "posterior_mean = post_mean(prior_var,data_var,n,data_mean,prior_mean)\n",
    "\n",
    "posterior_std = post_std(prior_var,data_var,n)\n",
    "\n",
    "print(r'likelihood mean and error are {:.3f} +/- {:.3f} cm'.format(data_mean,err_mean))\n",
    "\n",
    "print('posterior mean and std are {:.3f} +/- {:.3f} cm'.format(posterior_mean,posterior_std))\n",
    "\n",
    "plt.figure(figsize=(20,6))\n",
    "# for plotting\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.hist(ht,density=True,label='data')\n",
    "plt.legend(loc='upper left',fontsize=14)\n",
    "plt.xlim(155,180)\n",
    "plt.ylim(0,0.25)\n",
    "plt.xlabel('height in cm')\n",
    "plt.ylabel('PDF')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.plot(d,norm.pdf(d,data_mean,err_mean),label='likelihood',c='purple') #likelihood\n",
    "plt.plot(d,norm.pdf(d,prior_mean,np.sqrt(prior_var)),label='prior',c='red') # prior distribution\n",
    "plt.legend(loc='upper left',fontsize=14)\n",
    "plt.xlim(155,180)\n",
    "plt.ylim(0,0.25)\n",
    "plt.xlabel('height in cm')\n",
    "plt.ylabel('PDF')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.plot(d,norm.pdf(d,data_mean,err_mean),label='likelihood',c='purple') #likelihood\n",
    "plt.plot(d,norm.pdf(d,prior_mean,np.sqrt(prior_var)),label='prior',c='red') # prior distribution\n",
    "plt.plot(d,norm.pdf(d,posterior_mean,posterior_std),label='posterior',c='blue',lw=4)\n",
    "plt.xlim(155,180)\n",
    "plt.ylim(0,0.25)\n",
    "plt.axvline(posterior_mean,label='post mean')\n",
    "plt.xlabel('height in cm')\n",
    "plt.legend(loc='upper right',fontsize=14)\n",
    "plt.ylabel('PDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this tell us? We can see that the prior is quite far from data. The data has a few peaks and is not really Gaussian! but we do expect the population to be Gaussian. The peaks at heights $<$160cm caused the likelihood PDF to peak at a lower mean than the previous measurement (the prior). The posterior (given the prior information) favours the second group of data points but has a wider distribution.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivation: Mean and Variance from the Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did we get the analytical expressions for the mean and variance of a normally distributed posterior? \n",
    "\n",
    "$p(\\theta | \\hat{X}) \\propto  p(\\hat{X} | \\theta) p(\\theta) $\n",
    "\n",
    "$ \\propto \\mbox{exp} \\left[ - \\dfrac{ (\\hat{X} - \\theta)^2} {2\\sigma^2/n} \\right] \\mbox{exp} \\left[ -\\dfrac{(\\theta - \\mu_0)^2} {2\\sigma_0^2} \\right] $\n",
    "\n",
    "$ \\propto \\mbox{exp} \\left[ -\\dfrac{1}{2} \\left( \\dfrac{\\hat{X}^2 - 2\\theta \\hat{X} + \\theta^2} {\\sigma^2/n} + \\dfrac{\\theta^2 -2\\theta\\mu_0 + \\mu_0^2} {\\sigma_0^2} \\right)  \\right]$\n",
    "\n",
    "\n",
    "$ \\propto \\mbox{exp}  \\left[  -\\dfrac{1}{2} \\left( \\dfrac{\\theta^2}{\\sigma^2/n} - \\dfrac{2\\theta\\hat{X}}{\\sigma^2/n} +\\dfrac{\\theta^2}{\\sigma^2_0} - \\dfrac{2\\theta\\mu_0}{\\sigma_0^2} \\right) \\right]$\n",
    "\n",
    "\n",
    "$ \\propto \\mbox{exp}  \\left[  -\\dfrac{1}{2} \\left( \\theta^2 \\left( \\dfrac{1}{\\sigma^2/n} + \\dfrac{1}{\\sigma_0^2} \\right) - 2\\theta \\left(  \\dfrac{\\hat{X}}{\\sigma^2/n} + \\dfrac{\\mu_0}{\\sigma_0^2} \\right) \\right) \\right] $\n",
    "\n",
    "\n",
    "Now, if we consider that $\\theta$ were a normal distribution, then\n",
    "\n",
    "$f(\\theta) \\propto \\mbox{exp} \\left[ -\\dfrac{(\\theta - \\hat{\\theta})^2}{2 \\hat{\\sigma}^2} \\right]$\n",
    "\n",
    "$\\propto \\mbox{exp} \\left[ -\\dfrac{1}{2} \\left( \\dfrac{\\theta^2}{\\hat{\\sigma}^2}  - \\dfrac{2 \\theta \\hat{\\theta}}{\\hat{\\sigma}^2} \\right) \\right]$\n",
    " \n",
    " \n",
    "which has the same form as the expansion of the product of the likelihood and prior above. So the posterior must also be a normal distribution, and we can match up the terms containing $\\theta^2$ and $2\\theta$ from the relations above. From matching the $\\theta^2$ terms, we get,\n",
    "\n",
    "$\\hat{\\sigma}^2 = \\left(  \\dfrac{1}{\\sigma^2/n} + \\dfrac{1}{\\sigma_0^2}  \\right)^{-1}$,\n",
    "\n",
    "which after a little algebra, gives:\n",
    "\n",
    "$\\hat{\\sigma}^2 =  \\dfrac{\\sigma_0^2 \\sigma^2/n} {\\sigma_0^2 + \\sigma^2/n}.$\n",
    "\n",
    "Similarly, we can match up the $2\\theta$ terms to get,\n",
    "\n",
    "$\\dfrac{\\hat{\\theta}} {\\hat{\\sigma}^2} = \\dfrac{\\hat{X}}{\\sigma^2/n} + \\dfrac{\\mu_0}{\\sigma_0^2}$\n",
    " \n",
    "\n",
    "$ \\hat{\\theta} = \\dfrac{\\sigma_0^2 \\sigma^2/n} {\\sigma_0^2 + \\sigma^2/n} \\left( \\dfrac{\\hat{X}}{\\sigma^2/n} + \\dfrac{\\mu_0}{\\sigma_0^2}   \\right)$\n",
    "\n",
    "$\\hat{\\theta} = \\dfrac{\\sigma_0^2}{\\sigma_0^2 + \\sigma^2/n} \\hat{X}   +  \\dfrac{\\sigma^2/n} {\\sigma_0^2 + \\sigma^2/n} \\mu_0 $\n",
    "\n",
    "The expressions above give, respectively the mean ($\\hat{\\theta}$) and variance ($\\hat{\\sigma^2}$) of the **posterior** that describes the probability of $\\theta$. More importantly, we can see that our mean of the posterior, $\\hat{\\theta}$, depends on *both the mean and variance of the data*, $\\hat{X} ~~\\text{and} ~~\\sigma^2$, and *the mean and variance of the prior*, $\\mu_0 ~~\\text{and}~~ \\sigma_0^2.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binomial/Bernoulli Likelihood - beta prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytical expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the normal likelihood, Binomial/Bernoulli distributions are probably the second most common form, since it covers a wide range of problems, such the ski test we saw earlier in the course, drug trials, etc. The conjugate prior to this is is a beta function determined by shape parameters $a$ and $b$.\n",
    "\n",
    "The posterior mean is then given by,\n",
    "\n",
    "$\\hat{\\theta}  = \\dfrac{ \\nu }{ N }\\, \\dfrac{ N }{ N + a + b }~ +~ \\dfrac{ a }{ a + b} \\, \\dfrac{a + b}{ N + a + b }$\n",
    "\n",
    "and the variance is \n",
    "\n",
    "$\\sigma^2  = \\dfrac{ \\hat{\\theta}(1 - \\hat{\\theta})}  {\\nu+a + N-\\nu+b + 1}.$\n",
    "\n",
    "We can roughly associate $a$ with the number of successes you previously observed and $(a + b) \\sim n$  with the number of trials you observed. So if you have a guess for the prior mean $m$, you can try\n",
    "\n",
    "$a=mn$\n",
    "\n",
    "$b=1-m$\n",
    "\n",
    "eg if you have a coin but do not know if it is biased towards heads and tails then $a = b =0.5$ is a safe assumption. If you repeat the experiment 6 times and coin seems to be fair then a good choice might be $a=b=3$.  Below are some examples of priors using beta functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "a = [0.5,40.]\n",
    "b = [0.5,40.]\n",
    "\n",
    "x = np.linspace(0, 1, 1002)[1:-1]\n",
    "\n",
    "for i in range(0,len(a)):\n",
    "    dist = beta(a[i],b[i])\n",
    "    plt.plot(x, dist.pdf(x),label=[a[i],b[i]],lw=2)\n",
    "    \n",
    "plt.xlim(0, 1)\n",
    "plt.legend()\n",
    "plt.ylabel('density')\n",
    "plt.xlabel('theta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice let's say we're interested in whether a coin is fair. Someone else has previously thrown the coin 50 times and recorded 20 heads, therefore we already know something about the coin. We then do our own sampling by flipping it 10 times and record 7 heads.  What we're doing is combining the prior information with our data to get the parameter we want.  The animation below shows the probability density of the prior (light blue), likelihood (red) based on our measurements, and the posterior (dark blue) if the sampling numbers are increased.   You can see that as the sampling number increases, the posterior peak rises and narrows, getting closer to the likelihood.  \n",
    "\n",
    "![animated](https://github.com/haleygomez/Data-Analysis-2021/raw/master/blended_exercises/Chapter6/animatedpost.gif)\n",
    "\n",
    "The difference between a credible interval and a confidence interval decreases as the number of data taken increases. The advantage of using a credible interval is most clear when the sample size is small or if it's difficult to take more data, eg giving patients different types of medicine.   Below the animation shows the change in the credible interval (blue) and the confidence interval (red) for the coin as the sample size increases.\n",
    "\n",
    "![credible](https://github.com/haleygomez/Data-Analysis-2021/raw/master/blended_exercises/Chapter6/credible.gif)\n",
    "\n",
    "These animations are from this excellent [post](https://towardsdatascience.com/do-you-know-credible-interval-e5b833adf399)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivation: Mean and Variance from Binomial Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did we derive the analytical approximations to the posterior mean and variance for the Bernoulli/Binomial case?\n",
    "\n",
    "Remember that Bernoulli and Binomial distributions both have the form,\n",
    "\n",
    "$p(\\nu | N, \\theta) \\propto \\theta^{\\nu} (1 - \\theta)^{(N - \\nu)}$.\n",
    "\n",
    "In the case of the Bernoulli distribution, which focuses on a single outcome, the leading constant is 1, while in the case of the Binomial distribution, which accounts for any combination of the $\\nu$ successes in $N$ trails, the leading constant is given by the binomial factor ${N \\choose \\nu} = \\dfrac{ N! }{\\nu!(N-\\nu)!}$.\n",
    "\n",
    "Remember that the functional family that has the same form as Bernoulli and Binomial distributions are called **beta distributions**. The mean and variance of the beta distribution are given by,\n",
    "\n",
    "\n",
    "$\\hat{\\theta}_{B} = \\dfrac{a}{a+b}$\n",
    "\n",
    "$\\sigma_{B}^2  = \\dfrac{ \\hat{\\theta}(1 - \\hat{\\theta})}  {a + b + 1}$.\n",
    "\n",
    "\n",
    "One can consider the prior as if it is reporting previously observed data. In this case, we can equate the $a-1$ and $b-1$ in the beta distribution to the $\\nu$ and $N-\\nu$ terms in the Bernoulli and Binomial distributions. This can the be used to guide your choice of $a$ and $b$. \n",
    "\n",
    "For example, if you think the coin is a joke coin, but do not know whether it is biased towards heads or tails, then $a = b = 0.5$ is perhaps a good choice. If you think the coin is probably fair, based on a low number (around 5-6) of observations in the past, then $a = b = 4$ might be a good choice, or larger values of $a$ and $b$ if you had a larger sample in the past. Given the number of events in the previous trial, and its outcome, you can use this to calculate your $a$ and $b$ for the Bayes calculation.\n",
    "\n",
    "The full form of a Bayesian analysis of a Bernoulli likelihood with beta prior is,\n",
    "\n",
    "$ p(\\theta |\\nu, N)  = \\dfrac{p(\\nu, N \\,|\\, \\theta)\\,p(\\theta)}{ p(\\nu, N)} $\n",
    "\n",
    "$ p(\\theta |\\nu, N)  = \\dfrac{\\theta^{\\nu} \\, (1 - \\theta)^{(N - \\nu)} \\, \\theta^{(a - 1)} \\, (1 - \\theta)^{(b - 1)} } {B(a, b)\\, p(\\nu, N)}$\n",
    "\n",
    "$ p(\\theta |\\nu, N) = \\dfrac{\\theta^{(\\nu + a) - 1} (1 - \\theta)^{(N - \\nu +b) -1} }   {B(\\nu + a, ~ N-\\nu + b)}$.\n",
    "\n",
    "Although the powers of $\\theta$ and $(1-\\theta)$ probably made sense there, you are probably wondering where the magic on the denominator came from.   The clue is in the way we wrote the powers in the numerator, where you can see that we have deliberately written them in the form of a beta distribution, where \n",
    "\n",
    "$a \\equiv \\nu + a$,\n",
    "\n",
    "and,\n",
    "\n",
    "$b \\equiv N - \\nu + b$. \n",
    "\n",
    "This allows us to replace the complicated integral in the denominator with the standard normalisation for a beta distribution of the form beta$(\\nu + a, ~ N - \\nu +b)$, which is simply $B(\\nu + a, ~ N-\\nu + b)$.  \n",
    "\n",
    "*Important: you must include the beta normalising denominator (from the beta distribution - see Chapter 3) in your posterior calculations, because it changes the shape of the beta function!*\n",
    "\n",
    "Once again, we can look at the interplay between the mean predicted by the data (via the likelihood), and the mean predicted by prior. The prior mean is $a / (a + b)$. \n",
    "\n",
    "The mean of the posterior can then be found by substituting $a_\\mbox{post} \\equiv \\nu + a$ and $b_\\mbox{post} \\equiv N - \\nu + b$ into the same equation. Wen can then rearrange the posterior mean $\\hat{\\theta}$ to get,\n",
    "\n",
    "$\\hat{\\theta} = \\dfrac{ \\nu + a_\\mbox{post} }{N + a_\\mbox{post} + b_\\mbox{post}} = \\dfrac{ \\nu }{ N }\\, \\dfrac{ N }{ N + a + b }~ +~ \\dfrac{ a }{ a + b} \\, \\dfrac{a + b}{ N + a + b }$\n",
    "\n",
    "where we see once again that we weight the data and the prior, by their uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if we know nothing about the prior?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the absence of any other information, a **uniform** (or constant) prior is often assumed.  This can be interpreted as meaning that all possible values are equally likely, or you have no prior information and you cannot distinguish between possible values.  Note that a uniform prior can be used by setting the prior to 1 over the range required, or by using a beta prior with $a=b=1$.  Here is an example of this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1.0\n",
    "b = 1.0\n",
    "\n",
    "x = np.linspace(0, 1, 1002)[1:-1]\n",
    "\n",
    "dist = beta(a,b)\n",
    "plt.plot(x, dist.pdf(x),label='a=1,b=1')\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it sounds like it would make no difference, it turns out that a uniform prior can still add information and change the probabilities, particularly if your experiment has low success rates or low numbers of trials (for Binomial events say).   Think about it this way: using a uniform prior in a Bernoulli experiment is equivalent to adding two observations to the data: one success and one fail (or one heads, one tails) etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#4290C4>Example</font>\n",
    "\n",
    "Suppose we have an experiment running $N$ Bernoulli trials where $\\nu$ successes are recorded.  The unknown probability of success is $p$. A suitable uniform prior would be $p(\\theta) = 1$ for all values.   One might think we do not gain anything from a uniform prior, but using a uniform prior in a Bernoulli experiment is equivalent to adding two observations to the data, one success and one fail (or one heads, one tails).  Here we will prove it can make a difference.\n",
    "\n",
    "- Compare expressions for the expectation value expected from the data (the mean of the Bernoulli distribution) with that from the posterior.<br><br>\n",
    "\n",
    "- Calculate these for small $N$ and $\\nu$ and large $N$ and $\\nu$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color=#c38241> Solution</font>\n",
    "\n",
    "Click below to see the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $\\nu$ successes and $N$ trials, the Bernoulli mean is given by $p=\\nu/N$. \n",
    "\n",
    "The prior is a beta function with $a=1,b=1$.\n",
    "\n",
    "The posterior mean for this family, with a beta prior is given by\n",
    "\n",
    "${\\rm experiment~ mean} = \\dfrac{\\nu}{N}$\n",
    "\n",
    "so\n",
    "\n",
    "${\\rm posterior~ mean} = \\dfrac{\\nu}{N}\\dfrac{N}{N+a+b} + \\dfrac{a}{a+b}\\dfrac{a+b}{N+a+b}$ for $a$ and $b$ from priors.\n",
    "\n",
    "Or we can write\n",
    "\n",
    "${\\rm posterior~ mean} = \\dfrac{\\nu+a_{\\rm post}}{N+a_{\\rm post}+b_{\\rm post}}$ where $a_{\\rm post}$ and $b_{\\rm post}$ are given by $\\nu+a$ and $N-\\nu+b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_mean_bin(n,nu,a,b):\n",
    "    a_post = nu + a\n",
    "    b_post = n - nu + b\n",
    "    return (nu+a)/(n+a+b)\n",
    "\n",
    "def bern_mean(n,nu):\n",
    "    return nu/n\n",
    "\n",
    "# let's test some values of nu_test,N_test\n",
    "nu_test = [2.,8.,80.,800.]\n",
    "N_test = [10.,10.,100.,1000.]\n",
    "\n",
    "#\n",
    "a_prior = 1.\n",
    "b_prior = 1.\n",
    "\n",
    "for i in range(0,len(nu_test)):\n",
    "    print(\"N=\",N_test[i],\"nu=\",nu_test[i])\n",
    "    print('ratio between values from data + posterior is \\\n",
    "    {:.3f}'.format(bern_mean(N_test[i],nu_test[i])/post_mean_bin(N_test[i],nu_test[i],a_prior,b_prior)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for the same $N$, the lower the success rate $\\nu$, the larger the difference between the posterior and the data values are - ie the uniform prior does affect the estimate of $\\theta$ from the posterior.  Difference is smaller for larger $N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Evidence term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you are probably wondering why we've neglected the evidence term! \n",
    "\n",
    "The evidence term is a number - it does not affect the shape of the distribution, just the absolute values of probability. The evidence term is just a normalisation for the problem. Often, we can ignore the evidence. For example when we just care the mean and variance of the posterior, the normalisation is not important. Also, if we simply want to the know the ratio of $\\theta$ taking two values, we again don't need to know the normalisation of the posterior, so we can ignore the evidence. Similarly, if we are just interested in finding the overall shape of the posterior.\n",
    "\n",
    "However, we've established that for the case of a normal likelihood, and a normal prior, the posterior is also normally distributed. Also, we've already worked out the width parameter of the normal, so in this case, it is trivial to normalise the posterior, and thus create a true PDF.\n",
    "\n",
    "For problems where we really do want to know the actual probabilities, but where the maths is tricky, we can still work without evaluating the evidence in many cases. For example, one can get a crude approximation to a normalised posterior by first making a *histogram* of the posterior, and then numerically integrating to find the total area under the histogram. If one then divides the original histogram by this area, the result is a normalised histogram of the posterior, this is an approximation to the posterior's underlying PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credible Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outcome of Bayes Theorem gives us the posterior which in these cases provides us with the probability density function for the parameter $\\theta$ given the data and how likely you think this is. So if the parameter is outside the credible interval we say it's not credible, if it lies within 95% of the credible interval we say it is credible.\n",
    "\n",
    "So in Bayesian statistics, a credible interval is an interval within which an unobserved parameter value falls with a particular probability.\n",
    "\n",
    "Recall that in Bayesianism, the probability distributions reflect our degree of belief. So when we compute the credible region it is equivalent to saying\n",
    "\n",
    "- \"Given our observed data, there is a 95% probability that the true value of the mean falls within the CR\" - Bayesians\n",
    "\n",
    "In frequentism, on the other hand, $\\mu$ is considered a fixed value and the data (and all quantities derived from the data, including the bounds of the confidence interval) are random variables. So the frequentist confidence interval is equivalent to saying\n",
    "\n",
    "- \"There is a 95% probability that when I compute confidence intervals from data of this sort, the true mean will fall within the confidence interval.\"- Frequentists \n",
    "\n",
    "Here's another way again:\n",
    "\n",
    "Suppose we read that the observed data $D_{\\rm obs}$ support conclusion $C$. How do the two parties see this?\n",
    "\n",
    "- \"C was selected with a procedure that is right 95% of the time over a set of $D$ that includes $D_{\\rm obs}$.\"- Frequentist \n",
    "\n",
    "- \"The strength of the chain of reasoning from the model and $D_{\\rm obs}$ to concluding C has probability 0.95.\" - Bayesian\n",
    "\n",
    "Credible intervals for Gaussians produce similar results to confidence intervals, but this is simply because of the properties of Gaussians.\n",
    "\n",
    "Note that credible intervals are also known as high density intervals. These are used in many areas of science, in particular in gravitational wave astronomy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#4290C4>Example</font>\n",
    "\n",
    "Suppose you are told \"Here is a confidence interval from the Large Hadron Collider experiment.\" What does it mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color=#c38241> Solution</font>\n",
    "\n",
    "Click below to see the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways you could answer the question:\n",
    "\n",
    "1. “There is 95% probability/plausibility/likelihood that the population parameter lies in the interval.”\n",
    "\n",
    "2. “If we repeat the experiment infinitely many times, 95% of the experiments will capture the population parameter in their confidence intervals.”\n",
    "\n",
    "The first answer is wrong. The first statement is interpreting a *Bayesian credible interval*. The second is the correct interpretation of a frequentist confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#4290C4>Example</font>\n",
    "\n",
    "We are given a coin at random, and asked to perform 50 flips. We find that heads comes up 35 of the 50 times. We want to know if the coin is fair. Plot the likelihood, prior and posterior distributions on one plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color=#c38241> Solution</font>\n",
    "\n",
    "Click below to see the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of obtaining the resulting series of heads (success) and tails (fail) is given by the Binomial distribution (since it is one coin flipped in a sequence of events/successes.\n",
    "\n",
    "$p(\\nu=35|N=50,\\theta) = \\theta^N(1-\\theta)^{(N-\\nu)}$\n",
    "\n",
    "Since we were given the coin at random and we know nothing about it, we will adopt a uniform prior.\n",
    "\n",
    "$p(\\theta) = 1$ f or $0 < \\theta < 1$.\n",
    "\n",
    "Note that in this example I will write this simple as $p=1$ for all $x$  but a uniform prior for Bernoulli/Binomial family is equivalent to a beta function with $a=1,b=1$, so we could also write it as a beta function (we can also be written in the format = Beta(1,1)).\n",
    "\n",
    "Our null hypothesis is that the coin is fair ($\\theta=0.5$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "nu = 35\n",
    "N=50\n",
    "\n",
    "# for plotting\n",
    "nsteps=100\n",
    "\n",
    "h = np.arange(0,1,1./nsteps)\n",
    "\n",
    "likelihood_coin = (math.factorial(N)/(math.factorial(nu)*(math.factorial(N-nu))))*h**nu * (1 - h)**(N - nu) \n",
    "\n",
    "# prior is constant = 1 for all x \n",
    "prior_coin = [1.0 for i in range(0,len(h))]\n",
    "\n",
    "# posterior = likelihood x prior\n",
    "posterior_coin = likelihood_coin*prior_coin\n",
    "\n",
    "#let's save an array of x and y for working out credible intervals later\n",
    "\n",
    "plt.plot(h,likelihood_coin,label='likelihood')\n",
    "plt.plot(h,posterior_coin,'.',label='posterior')\n",
    "\n",
    "#plt.xlim(0,1)\n",
    "plt.ylabel('PDF unnormalised')\n",
    "plt.xlabel('theta')\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#4290C4>Example</font>\n",
    "\n",
    "Now estimate the 95% credible intervals and the value we would expect for a fair coin $\\theta = 0.5$. For a ROPE we could set this to something like $\\theta = 0.5 \\pm 0.025$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color=#c38241> Solution</font>\n",
    "\n",
    "Click below to see the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So is it fair? Let's assume we're approaching gaussian distribution for $N=50$ and simply use the fact that the mean $\\pm 1.96 \\sigma$ gives 95% probability intervals.\n",
    "\n",
    "To do this we need to calculate the mean and standard deviation of the posterior. We can do this using the analytic expressions listed above for a bernoulli likelihood with beta prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior_mean \n",
    "nu =35.\n",
    "N=50.\n",
    "\n",
    "# uniform prior = beta(1,1) ie a=1, b=1\n",
    "a = 1.\n",
    "b = 1.\n",
    "\n",
    "# posterior mean + std from analytical approx in lecture notes\n",
    "posterior_mean_coin = np.float((nu+a)/(N+a+b))\n",
    "posterior_std_coin = np.sqrt( posterior_mean_coin*(1-posterior_mean_coin)/(nu+a+N-nu+b+1))\n",
    "\n",
    "# set up credible intervals = mean + / - 1.96 x sigma\n",
    "HDI_a = posterior_mean_coin+1.96*posterior_std_coin\n",
    "HDI_b = posterior_mean_coin-1.96*posterior_std_coin\n",
    "\n",
    "plt.plot(h,likelihood_coin,label='likelihood',c='purple')\n",
    "plt.plot(h,posterior_coin,'.',label='posterior',c='black',lw=2)\n",
    "\n",
    "# this makes nice shaded regions to show off where the ROPE is\n",
    "plt.axvspan(0.5-0.025,0.5+0.025,color='green',label='ROPE',alpha=0.3)\n",
    "plt.axvspan(HDI_b,HDI_a,color='pink',label='95% HDI',alpha=0.3)\n",
    "\n",
    "plt.axvline(0.5,color='green',label='theta=0.5')\n",
    "plt.ylabel('PDF unnormalised')\n",
    "plt.xlabel('theta')\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fair coin ($\\theta=0.5$) falls outside the 95% HDI, so we can reject the null hypothesis that the coin is fair. (Note it could also be that our ROPE was too stringent).\n",
    "\n",
    "Note that in python we could determine credible intervals if we assume that the posterior were normal by (i) using `scipy.stats` `norm.interval(0.95,mean,std)` function or (ii) numpy's `percentile(data,95)` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#4290C4>Example</font>\n",
    "\n",
    "Let's return to the question earlier about the student heights. Now we are going to assume the null hypothesis is that the height of a 20 year old student is  $>170$ cm. Determine the 95% credible intervals for the posterior. Plot this range over your posterior distribution. You can do this using lines axvline or axvspan to colour the entire range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color=#c38241> Solution</font>\n",
    "\n",
    "Click below to see the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can use norm.interval to get the interval out for 95% \n",
    "# note that 95% is roughly equivalent to 2xstandard deviations so they can use that\n",
    "HDI_1,HDI_2 = norm.interval(0.95,posterior_mean,posterior_std)\n",
    "print('95% confidence intervals are {:.3f} and {:.3f} cm'.format(HDI_1,HDI_2))\n",
    "\n",
    "plt.plot(d,norm.pdf(d,posterior_mean,posterior_std),label='posterior',c='blue',lw=2)\n",
    "plt.axvline(posterior_mean,label='mean posterior',color='blue',alpha=0.5)\n",
    "plt.axvline(posterior_mean+posterior_std,color='blue',ls='-.',alpha=0.5)\n",
    "plt.axvline(posterior_mean-posterior_std,color='blue',ls='-.',alpha=0.5)\n",
    "plt.axvspan(HDI_1,HDI_2,facecolor='red', alpha=0.2, label = '95% HDI')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlim(150,180)\n",
    "#plt.ylim(0,0.3)\n",
    "plt.xlabel('height in cm')\n",
    "plt.ylabel('PDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to test null hypothesis that height of a 20 year old student is $>170$cm. Can we reject the null hypothesis based on our data? \n",
    "\n",
    "Let's use everything $>170$cm as a reasonable region (our ROPE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# can use norm.interval to get the interval out for 95% \n",
    "HDI_1,HDI_2= norm.interval(0.95,posterior_mean,posterior_std)\n",
    "print('95% confidence intervals are {:.3f} and {:.3f} cm'.format(HDI_1,HDI_2))\n",
    "\n",
    "plt.plot(d,norm.pdf(d,posterior_mean,posterior_std),label='posterior',c='blue',lw=2)\n",
    "plt.axvline(posterior_mean,label='mean posterior',color='blue',alpha=0.5)\n",
    "plt.axvline(posterior_mean+posterior_std,color='blue',ls='-.',alpha=0.5)\n",
    "plt.axvline(posterior_mean-posterior_std,color='blue',ls='-.',alpha=0.5)\n",
    "plt.axvspan(HDI_1,HDI_2,facecolor='red', alpha=0.2, label = '95% HDI')\n",
    "plt.axvspan(170,170+10,facecolor='purple', alpha=0.5, label = 'ROPE')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlim(150,180)\n",
    "plt.ylim(0,0.3)\n",
    "plt.xlabel('height in cm')\n",
    "plt.ylabel('PDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROPE is just within the 95% confidence interval, so although we cannot reject the null hypothesis that students heights are $>170$cm as it lies *just within our credible region*, the data does not give strong evidence for the null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some real life examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The incredible discovery of gravitational waves existing in the Universe in 2015 led to the award of a Nobel Prize in 2017. The gravitational waves were from a binary neutron star merger, also observed using electromagnetic telescopes sensitive to light across the entire electromagnetic spectrum.  As well as discovering a new kind of physics, the observations allowed scientists to combine the galaxy distance measured from the gravitational-wave data with radial velocity measurements from the electromagnetic data. In doing so, they were able to make an entirely independent measurement of an important quantity in cosmology: the present-day [expansion rate of the Universe](https://www.ligo.org/science/Publication-GW170817Hubble/).  The figure below shows the measurement of the Hubble constant, $H_0$ (the expansion rate of the Universe) determined using the gravitational wave signals. The relative probability of different values of $H_0$ is represented by the solid blue curve- with a peak at $70 \\rm \\,km\\,s^{-1} Mpc^{-1}$. \n",
    "\n",
    "    Dashed and dotted blue lines show the 68.3% and 95.4% credible intervals for $H_0$. For comparison the green and orange bands represent measurements of $H_0$ from two experiments using electromagnetic data: the Planck satellite and the SHoES analysis (exploding stars and twinkling lights). The darker and lighter coloured bands indicate 68.3% and 95.4% credible intervals for these values.  Scientists were able to conclude from this figure that the Planck and SHoES measurements of the expansion rate of the Universe are not in agreement with each other at the 95.4% probability level. However, the gravitational-wave result is, consistent with both the Planck and SHoES values. *Figure reproduced from this [site](https://www.ligo.org/science/Publication-GW170817Hubble/).*\n",
    "    \n",
    "    <img src=\"https://github.com/haleygomez/Data-Analysis-2021/raw/master/blended_exercises/Chapter6/hubble_posterior.png\" width=\"500\">\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The Office of National Statistics uses a Bayesian model and quotes 95% confidence intervals for their infection rates from COVID-19 in England. They state that:\n",
    "\n",
    "    >*During the most recent week of the study, we estimate that 27,100 people in England had the coronavirus\n",
    "(COVID-19) (95% credible interval: 19,300 to 36,700).1 This equates to 0.05% (95% credible interval: 0.04% to 0.07%) of the population in England or around 1 in 2,000 people (95% credible interval: 1 in 2,800 to 1 in 1,500). This is based on statistical modelling of the trend in rates of positive nose and throat swab results.* - [Source](https://www.ons.gov.uk/peoplepopulationandcommunity/healthandsocialcare/conditionsanddiseases/bulletins/coronaviruscovid19infectionsurveypilot/englandandwales4september2020/pdf)\n",
    "\n",
    "<img src=\"https://github.com/haleygomez/Data-Analysis-2021/raw/master/blended_exercises/Chapter6/covidons.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to tackle the **Chapter 6 quiz** on Learning Central and the [Chapter 6 yourturn notebook](https://github.com/haleygomez/Data-Analysis-2021/blob/master/blended_exercises/Chapter6/Chapter6_yourturn.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is some code to get pretty highlighted cells for the questions - ignore this\n",
    "from IPython.display import HTML\n",
    "style1 = \"<style>div.warn { background-color: #fcf2f2;border-color: #dFb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;}</style>\"\n",
    "HTML(style1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers some worked examples and some examples for you to try relating to **Block A, Chapter 1** in the notes (Introduction to Probability).  This is practice and core material for coursework 1. The green questions are those most closely related to the assessed work for this module. *After completing this notebook, you can attempt QNs 1 and 4 on coursework 1.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revision of concepts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The axioms of probability are:\n",
    "\n",
    "Axiom 1 : $0 \\le P(A) \\le 1$\n",
    "\n",
    "Axiom 2 : $P(\\Omega) = 1$\n",
    "\n",
    "Axiom 3 : $P(A_1 \\cup A_2 \\cup A_3 ...) = P(A_1)+P(A_2)+(P(A_3)+...$\n",
    "\n",
    "Moving from conditional probabilities to Bayes Theorem which states that:\n",
    "\n",
    "$ P (A|B) = \\dfrac{P(A \\cap B) }{P(B)} \\rightarrow \\dfrac{P(B|A)P(A)}{P(B|A)P(A)+P(B|A^c)P(A^c)}$ \n",
    "\n",
    "Bayes Rule is normally used to determine the probability of a specific model, $\\theta$, given some data D, such that\n",
    "\n",
    "$P(\\theta|D) = \\dfrac{P(D|\\theta) P(\\theta)}{P(D)}$ where\n",
    "\n",
    "where $P(D|\\theta)$ is the *likelihood*, $P(\\theta)$ is the *prior*, and $P(D)$ is the *evidence*. $P(\\theta|D)$ is the *posterior*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People feel uncomfortable about ‘priors’, since often they are a ‘best guess’\n",
    "\n",
    "Indeed, different analysts may have differing opinions about what the prior for a given experiment should be.  Although ‘frequentists’ disagree with the use of priors, note that technically they do assume one: they assume that all is equally likely (i.e. a ‘flat’ prior).\n",
    "\n",
    "Clearly this is also wrong.  So priors are useful — but they must be clearly stated. They provide a formal means for the analyst to include previous information that is relevant to the experiment. They also allow you test whether the model is good.\n",
    "\n",
    "Bayesian vs Frequentist:\n",
    "\n",
    "A Bayesian might argue “the prior probability is a logical necessity when assessing the probability of a model. It should be stated, and if it is unknown you can just use an uninformative (wide) prior” \n",
    "\n",
    "A frequentist might argue “setting the prior is subjective - two experimenters could use the same data to come to two different conclusions just by taking different priors”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian analysis has a somewhat formidable reputation for being extremely difficult… why is that?\n",
    "\n",
    "- In general, the denominator can be difficult to evaluate\n",
    "- Tricky integrals\n",
    "- Often require numerical solutions\n",
    "- Large (multivariate) parameter space\n",
    "- In the 20th century, the development of Monte Carlo Markov Chains have made the evaluation of the integrals and the probabilities much easier. \n",
    "\n",
    "You will learn more about this later in the course!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Worked example of Bayes Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine that a box contains five coins, one of which is a joke (J) coin, with heads on both sides. A coin is selected at random from the box, and flipped 3 times. The result is 3 heads (3H). What is probability that the coin is the trick coin?\n",
    "\n",
    "First, we should define what we are trying to work out. \n",
    "\n",
    "We are interested in $P(J | 3H)$. We will let the normal coin be denoted by $C$. So using Bayes Theorem we can write,\n",
    "\n",
    "$P(J | 3H) = \\dfrac{ P(3H | J) P(J)}  {P(3H) }$\n",
    "\n",
    "To get the probability of $P(3H)$ we need to add up all possibilities of getting it.\n",
    "\n",
    "$P(J | 3H) = \\dfrac{ P(3H | J) P(J)}  {P(3H | J) P(J) + P(3H | C) P(C)}$\n",
    "\n",
    "The probability of randomly selecting the joke coin is $P(J) = 1/5$. \n",
    "\n",
    "The probability of not selecting it, is $P(J^c) = 1 - 1/5 = 4/5 = P(C)$. \n",
    "\n",
    "The probability of getting 3 heads with the joke coin is 1, so \n",
    "\n",
    "$P(3H | J) = 1$\n",
    "\n",
    "The probability of getting 3 heads with a standard coin is $(1/2) \\times (1/2) \\times (1/2)$ (remember these are independent events), so\n",
    "\n",
    "$P(3H | C) = 1/8$\n",
    "\n",
    "$P(J | 3H) = \\dfrac{ 1 \\times 1/5}  {1 \\times 1/5 ~ + ~1/8 \\times 4/5} = 2 / 3$\n",
    "\n",
    "So there's a 66% chance the coin that we are seeing flipped is the joke coin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Your turn:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"warn\">** Question: ** <br><br>\n",
    "\n",
    "Write down in words what the following expressions mean:<br>\n",
    " \n",
    "- $P(B^c)$ <br>\n",
    "- $P(C \\cap D)$ <br>\n",
    "- $P(C \\cup D)$ <br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Answer: **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">**Question:** <br><br>\n",
    "You flip a coin 10 times. What is the probability that heads will not occur 5 times?    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Answer: **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">**Question:** <br><br>\n",
    "Define the terms: prior, likelihood, posterior in relation to Bayes Rule in terms of probability (use words).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">**Question:** \n",
    "\n",
    "Suppose you think you have a rare disease where 1 in 10,000 people are affected. You go to your doctor, and she performs a test. The test is of a high quality, and is correct 99% of the time.\n",
    "\n",
    "Unfortunately your results come back positive for the disease. What is your chance of having the disease? Is it (roughly): <br><br>\n",
    "\n",
    "a) 99% <br>\n",
    "b) 90% <br>\n",
    "c) 10% or <br>\n",
    "d) 1%? <br> <br>\n",
    "\n",
    "Repeat the same as above, but change 1 in 10,000 to 1 in 100. What would the chances of having the disease be now? </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">** Question: ** <br><br>\n",
    "\n",
    " Given that $P(A \\cap B) = P(B \\cap A)$, show that Bayes Theorem can be written as <br>\n",
    "\n",
    "$\\dfrac{P(B|A)P(A)}{P(B|A)P(A)+P(B|A^c)P(A^c)$}$  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=warn>  **Question:** <br><br>\n",
    "\n",
    "Find out (from your lecture notes or other source) the definition of a discrete and a continuous variable and give an example of each. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So in the end what is probability?\n",
    "\n",
    "Our examples of coin flipping, die rolling and card selecting, we introduced the notion that the probability of a particular outcome or event is simply the number of times that event occurs, divided by the number of all possible outcomes.\n",
    "\n",
    "But say you have a coin, and you want to know $P(H)$ -- how do you proceed? You could guess that the coin is fair and assign 0.5 to outcome heads/tails. But is the coin fair? One way you could test this is to perform lots of experiments (coin flips) and keep track of the outcome. If you do enough of these, eventually you will get an empirical measure,\n",
    "\n",
    "$P(H) = \\dfrac{n_H}{n_{\\rm flips}}$\n",
    "\n",
    "where $n_H$ is the number of heads that appeared in the experiment and $n_{\\rm flips}$ is the number of times you flipped the coin (and counted the result). But when do you stop? Well, that depends on how accurately you want to know $P(H)$. But for now, we will simply note that this type of determination of $P$ is *frequentist*, in that the probability is defined by counting the instances of occurrence.\n",
    "\n",
    "However, what about the probability that it will rain tomorrow? You can see straight away that such a probability is more difficult to define. In fact, the use of Bayes Theorem, and in particular the prior, introduces a much more vague idea that $P$ represents the belief that something will occur."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
